{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries \n",
    "\n",
    "Import the required libraries, including pandas for data handling, JSON for reading configuration files, OS for interacting with the operating system, and the Snowflake connector for connecting to Snowflake. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from snowflake.connector import connect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Configuration \n",
    "\n",
    "Read the configuration details from a JSON file, such as warehouse, database, schema, user, password, and account details. \n",
    "\n",
    "## Step 3: Read CSV File \n",
    "\n",
    "Read the CSV file using pandas, specifying the delimiter as a pipe (\"|\"). This loads the dataset into a DataFrame for inspection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Exploring_Snowflake/config.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1j/061k422d4rldkng0flthj3tr0000gn/T/ipykernel_85431/2514483974.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Exploring_Snowflake/config.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Define the schema, table name, and file path for a specific CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mschemaName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'schema'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtblName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'database'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Exploring_Snowflake/config.json'"
     ]
    }
   ],
   "source": [
    "with open('config.json', 'r') as file:\n",
    "    config = json.load(file)\n",
    "# Define the schema, table name, and file path for a specific CSV file\n",
    "schemaName = config['schema']\n",
    "tblName = config['database']\n",
    "\n",
    "file_path = 'dataset/items.csv'\n",
    "df = pd.read_csv(file_path,sep=\"|\")\n",
    "\n",
    "# Print the first 5 rows to understand the structure\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Connect to Snowflake \n",
    "\n",
    "Establish a connection to Snowflake using the loaded configuration details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection setup\n",
    "conn = connect(\n",
    "  user=config['user'],\n",
    "  password=config['password'],\n",
    "  account= config['account'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Create Warehouse, Database, and Schema (If Not Exists) \n",
    "\n",
    "Execute SQL commands to create the warehouse, database, and schema if they don't already exist. This ensures that the proper structure is in place for the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7fd0046c05d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after you log in, create a database, schema, and warehouse if they donâ€™t yet exist, using the CREATE DATABASE, CREATE SCHEMA, and CREATE WAREHOUSE commands.\n",
    "conn.cursor().execute(f\"CREATE WAREHOUSE IF NOT EXISTS {config['warehouse']}\")\n",
    "conn.cursor().execute(f\"CREATE DATABASE IF NOT EXISTS {config['database']}\")\n",
    "conn.cursor().execute(f\"USE DATABASE {config['database']}\")\n",
    "conn.cursor().execute(f\"CREATE SCHEMA IF NOT EXISTS {config['schema']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Set Context \n",
    "\n",
    "Use the \"USE\" statements to set the context to the correct warehouse, database, and schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7fd000bed1d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.cursor().execute(f\"USE WAREHOUSE {config['warehouse']}\")\n",
    "conn.cursor().execute(f\"USE DATABASE {config['database']}\")\n",
    "conn.cursor().execute(f\"USE SCHEMA {config['schema']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Create Table \n",
    "\n",
    "Define and execute the \"CREATE TABLE\" statement, specifying the table's schema. The IF NOT EXISTS clause ensures that the table is created only if it doesn't already exist. The schema includes data types and column names that match the CSV file's structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7fd00598e6d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the CREATE TABLE statement\n",
    "create_table_stmt = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {config['testtable']} (\n",
    "    pid INT,\n",
    "    manufacturer INT,\n",
    "    \"group\" STRING,\n",
    "    content STRING,\n",
    "    unit STRING,\n",
    "    pharmForm STRING,\n",
    "    genericProduct INT,\n",
    "    salesIndex INT,\n",
    "    category FLOAT,\n",
    "    campaignIndex STRING,\n",
    "    rrp FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute the CREATE TABLE statement\n",
    "conn.cursor().execute(create_table_stmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Define File Format \n",
    "\n",
    "Create a named file format in Snowflake that matches the CSV file's structure, specifying the CSV type with a pipe (\"|\") as the field delimiter and skipping the header. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7fd00598ec50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the CREATE FILE FORMAT statement\n",
    "create_file_format_stmt = \"\"\"\n",
    "CREATE OR REPLACE FILE FORMAT my_file_format\n",
    "  TYPE = 'CSV'\n",
    "  FIELD_DELIMITER = '|'\n",
    "  SKIP_HEADER = 1;\n",
    "\"\"\"\n",
    "\n",
    "# Execute the CREATE FILE FORMAT statement\n",
    "conn.cursor().execute(create_file_format_stmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Copy Data into Table\n",
    "\n",
    "Execute the \"COPY INTO\" command to import the data from the CSV file into the table using the defined file format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7fd005995710>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_into_stmt = \"\"\"\n",
    "COPY INTO testtable\n",
    "FROM @%testtable\n",
    "FILE_FORMAT = my_file_format;\n",
    "\"\"\"\n",
    "conn.cursor().execute(copy_into_stmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Put Data (Alternative Method) \n",
    "\n",
    "Alternatively, you can use the \"PUT\" command to upload the CSV file to a stage associated with the table, followed by the \"COPY INTO\" command to copy the data from the stage into the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7fd005e4d450>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Putting Data\n",
    "conn.cursor().execute(\"PUT file:///Users/varshasureshbabu/Desktop/Exploring_Snowflake/Dataset/items.csv* @%testtable\")\n",
    "conn.cursor().execute(\"COPY INTO testtable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note: The code snippet includes both the \"COPY INTO\" command directly from the CSV file (Step 9) and the \"PUT\" followed by \"COPY INTO\" commands (Step 10). Use either one of these approaches based on your specific requirements. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
